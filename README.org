# Can be used to toggle the export of footnotes
#+OPTIONS: f:t

# Set the header depth
#+OPTIONS: H:5

# Disable automatic toc
#+OPTIONS: toc:nil
#+OPTIONS: title:nil

# Can be used to enable unicode characters
# #+LATEX_COMPILER: lualatex % Seems to prevent row-color highlighting
# #+LATEX_HEADER: \usepackage{unicode-math}
# #+LATEX_HEADER: \usepackage[utf8x]{inputenc}
# #+LATEX_HEADER: \usepackage[mathletters]{ucs}

#+LATEX_HEADER: \setcounter{secnumdepth}{5}

#+TITLE: Robust, Intuitive Programming Language (~ripl~)
#+SUBTITLE: Motivation, Design, and Implementation
#+AUTHOR: Ian McCall
#+LATEX_HEADER: \usepackage[margin=0.6in]{geometry}

#+LATEX_HEADER: \usepackage[T1]{fontenc}
#+LATEX_HEADER: \usepackage{cmbright}
# #+LATEX_HEADER: \usepackage[scale=0.9]{sourcecodepro}
#+LATEX_HEADER: \usepackage{sourcecodepro}

#+LATEX_HEADER: \setcounter{tocdepth}{4}

# increase space between table and caption
#+LATEX_HEADER: \usepackage{caption}
#+LATEX_HEADER: \captionsetup[table]{skip=10pt}

# allows use of the H option for force a float to Here
#+LATEX_HEADER: \usepackage{float}

#+LATEX_HEADER: \usepackage{multicol}

#+LATEX_HEADER: \usepackage{adjustbox}

# Set size of verbatim font used in "example" orb blocks
#+LATEX_HEADER: \usepackage{verbatim}
#+LATEX_HEADER: \makeatletter
#+LATEX_HEADER: \def\verbatim@font{\fontsize{10}{10}\ttfamily}

#+LATEX_HEADER: \usepackage[utf8]{inputenc}

#+LATEX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage[dvipsnames, table]{xcolor}

#+LATEX_HEADER: \usepackage{titlesec}

# enables highlighting on inline code
# (requires redefining \texttt as well, see below)
#+LATEX_HEADER: \usepackage{soul}

# hyperlinke colors
#+LATEX_HEADER: \hypersetup{ colorlinks=true, linkcolor=black, urlcolor=blue }

# Used for both bulleted and enumerated lists
#+LATEX_HEADER: \usepackage{enumitem}

# Customize bulleted lists
#+LATEX_HEADER:  \setlist{noitemsep, topsep=4pt, itemsep=3pt}
#+LATEX_HEADER:  \setlistdepth{9}
#+LATEX_HEADER:   \setlist[itemize,1]{label=-}
#+LATEX_HEADER:   \setlist[itemize,2]{label=-}
#+LATEX_HEADER:   \setlist[itemize,3]{label=-}
#+LATEX_HEADER:   \setlist[itemize,4]{label=-}
#+LATEX_HEADER:   \setlist[itemize,5]{label=-}
#+LATEX_HEADER:   \setlist[itemize,6]{label=-}
#+LATEX_HEADER:   \setlist[itemize,7]{label=-}
#+LATEX_HEADER:   \setlist[itemize,8]{label=-}
#+LATEX_HEADER:   \setlist[itemize,9]{label=-}
#+LATEX_HEADER:   \renewlist{itemize}{itemize}{9}

# Space above footnotes
#+LATEX_HEADER: \addtolength{\skip\footins}{6pt}

# Space between footnotes
#+LATEX_HEADER: \addtolength{\footnotesep}{5pt} % {\baselineskip}

# Prevent footnotes from being split across multiple pages
#+LATEX_HEADER: \interfootnotelinepenalty=10000

# tabu enables footnotes in tables, though I haven't gotten it to work with resizebox
# #+LATEX_HEADER: \usepackage{tabu}
# #+LATEX_HEADER: \usepackage{tabularx}

# Customize enumerated/numbered lists
# options include \arabic, \roman, \alph and \Alph
#+LATEX_HEADER: \setlist[enumerate,1]{label={\arabic*.}}
#+LATEX_HEADER: \setlist[enumerate,2]{label={\alph*.}}

#+BEGIN_EXPORT latex
\titlespacing\section      {0pt} {4pt plus 4pt minus 2pt}{2pt plus 1pt minus 1pt}
\titlespacing\subsection   {0pt} {2pt plus 4pt minus 2pt}{2pt plus 1pt minus 1pt}
\titlespacing\subsubsection{0pt} {2pt plus 4pt minus 2pt}{2pt plus 1pt minus 1pt}

% Package that produces a similar result to the code below:
% #+LATEX_HEADER: \usepackage[parfill]{parskip}

\setlength\parindent{0pt} % sets indent to zero
\setlength{\parskip}{6pt} % changes vertical space between paragraphs

% Code listing settings
\lstdefinelanguage{ripl}{
    morekeywords=
      % definitions
      { block
      , define
      , match
      , struct
      , template
      , union
      % forms
      , if
      % types
      , f32
      , i32
      },
    sensitive=true, % keywords are not case-sensitive
    morecomment=[l]{;}, % l is for line comment
    morestring=[b]" % defines that strings are enclosed in double quotes " for balance in buffer ;)
}

\definecolor{DarkGray}    {rgb}{0.26, 0.26, 0.30}
\definecolor{DarkBlue}    {rgb}{0.20, 0.40, 0.80}
\definecolor{DarkGreen}   {rgb}{0.15, 0.50, 0.40}

\definecolor{LightGray}   {rgb}{0.94, 0.96, 0.96}
\definecolor{LightBlue}   {rgb}{0.40, 0.75, 1.00}
\definecolor{LightGreen}  {rgb}{0.40, 0.80, 0.60}

\lstset{language=ripl,
       % backgroundcolor=\color{White},
       % frame=single,
       % frame=half,
       % frame=leftline,
       xleftmargin=0.2in,
       xrightmargin=0.0in,
       captionpos=b,
       tabsize=2,
       % dark theme
       backgroundcolor=\color{DarkGray},
       basicstyle=\linespread{1.1}\color{LightGray}\fontsize{10}{10}\ttfamily,
       keywordstyle=\color{LightBlue},
       commentstyle=\color{LightGreen},
       % light theme
       backgroundcolor=\color{LightGray},
       basicstyle=\linespread{1.1}\color{DarkGray}\fontsize{10}{10}\ttfamily,
       keywordstyle=\color{DarkBlue},
       commentstyle=\color{DarkGreen},
  }

% Inline code highlighting
% \sethlcolor{LightGray}
% \let\OldTexttt\texttt
% \renewcommand{\texttt}[1]{\OldTexttt{\hl{#1}}}% will affect all \texttt

% Surrounding commands remove page number from title page
\clearpage\maketitle
\thispagestyle{empty}

\pagebreak

\begin{abstract}

\texttt{ripl} is a nascent programming language that is intended to combine the safety and purity of a language like Haskell, with the efficient, low-level capabilities of a language like C++ or Rust, and the metaprogramming capabilities of a language like Racket or D. The \texttt{ripl} compiler is written in Scala with an LLVM backend, and is still in development. This document provides an overview of \texttt{ripl}'s motivation, design and implementation, in addition to a quantitative comparison with other languages over a wide range of language features. The results of this comparison suggest that \texttt{ripl} is sufficiently different from existing languages to warrant its creation, and I believe it will offer a unique, productive, ergonomic, and performant middle-ground between high-level purely-functional languages and lower-level imperative languages, with some interesting new features as well.
\end{abstract}
\pagebreak

\begin{Large}
\textbf{Symbols in Section Names}
\end{Large}
\newline
\begin{small}
\texttt{+} Feature included in \texttt{ripl}
\newline
\texttt{-} Feature not included in \texttt{ripl}
\newline
\texttt{?} Feature may be included in future
\end{small}

\tableofcontents
\lstlistoflistings
\listoftables
\listoffigures

\newpage

#+END_EXPORT


* Introduction
~ripl~ is a nascent programming language and the subject of my undergraduate thesis at UBC. It is intended to combine the safety and purity of a language like Haskell, with the efficient, low-level capabilities of a language like C++ or Rust, and the metaprogramming capabilities of a language like Racket or D. The ~ripl~ compiler is written in Scala with an LLVM backend, and is still in development. This document provides an overview of ~ripl~'s motivation, design and implementation, in addition to a comparison with other languages.

#+BEGIN_EXPORT latex
The source of this document and the compiler can be found at \url{https://github.com/SongWithoutWords/ripl}.
#+END_EXPORT


* Notes on Language Specification

Although this document describes many of ~ripl~'s features, it is not a language specification. Instead the compiler and accompanying unit tests serve as the language specification. This is done for a number of reasons:

1. Code is more precise than English.
2. A compiler may be tested to validate it, whereas an English language specification may not.
3. An English language specification would add significant documentation overhead, and this time is better spent implementing the language.

A number of the features described in this document and that appear in code listings have not yet been implemented, and as such have not yet been specified.


* Project Status
The language and compiler are still in development and are not yet in a usable state. A detailed overview of the implementation status can be found in section [[Detailed Implementation Status]].


* Features at a Glance
- Compiled
- Strong, static typing
- Type inference
- Strict evaluation
- Type-safe discriminated unions
- Null safety
- Pattern matching
- Mutable data structures
- Type-level constraints on the mutability of data and purity of functions
- Name overloading
- Subtyping via built-in and user-defined implicit conversions
- Parametric polymorphism and type-level programming via templates
- Compile time function evaluation
- Expression oriented
- Readable, uniform syntax that is suitable for metaprogramming, inspired by [[https://sourceforge.net/p/readable/wiki/Home/][Readable Lisp S-expressions]][fn:4]

[fn:4] David A. Wheeler, Alan Manuel K. Gloria, Egil MÃ¶ller, Readale Lisp S-expressions,
https://sourceforge.net/p/readable/wiki/Home/


* Influence of Other Languages

Below is a list of languages mentioned in this document, ordered by the number of mentions. The order is consistent with my expectation, and provides a rough proxy for the influence of other languages on ~ripl~'s design. This influence doesn't necessarily suggest similarity, because ~ripl~'s design has been influenced both by example and counter-example. ~ripl~'s similarity to other languages is covered in section [[Distance of ~ripl~ from Other Languages]].

#+BEGIN_SRC emacs-lisp :exports results
(defun recursive-count (regex string start)
  (if (string-match regex string start)
      (+ 1 (recursive-count regex string (match-end 0)))
      0))

(defun count-occurences (regex string)
  (recursive-count regex string 0))

;; Search for words in the ASCII export so that we don't pick up on words in code blocks, comments, etc.
(setq ascii-export-contents
  (with-temp-buffer
    (insert-file-contents "README.txt")
    (buffer-string)))

(defun occurences-in-buffer (language-and-regex)
  (list
    (nth 0 language-and-regex) ; the name
    (-
      (count-occurences
        (nth 1 language-and-regex) ; the pattern
        ascii-export-contents)
      ; subtract the occurences of the name in this program and the resulting table
      (nth 2 language-and-regex))))

(setq case-fold-search nil)
(setq languages-to-search
 `(
    ("BASIC" "\\<BASIC\\>" 1)
    ("COBOL" "\\<COBOL\\>" 1)
    ("Fortran" "\\<Fortran\\>" 1)

    ("C" "\\bC[^a-zA-Z0-9\+\#]" 1)
    ("C++" "C\\+\\+" 1)
    ("C#" "C#" 1)
    ("D" "\\<D\\>" 1)
    ("Go" "\\<Go\\>" 1)
    ("Haskell" "Haskell" 1)
    ("Idris" "Idris" 1)
    ("Java" "\\<Java\\>" 1)
    ("JavaScript" "JavaScript" 1)
    ("Kotlin" "Kotlin" 1)
    ("Lisp, Racket, and Scheme", "Lisp\\|Racket\\|Scheme" 3)
    ("ML" "\\<ML\\>" 1)
    ("Python" "Python" 1)
    ("Rust" "Rust" 1)
    ("Scala" "Scala" 1)
))

`(
  ("Language" "Mentions in this Document")
  hline
  ,@(cl-sort
    (mapcar 'occurences-in-buffer languages-to-search)
    (lambda (a b) (> (nth 1 a) (nth 1 b)))))
#+END_SRC
#+ATTR_LATEX: :placement [H] :caption \caption{Language Mentions as a Proxy for Influence on \texttt{ripl}'s Design} \rowcolors{1}{}{gray!15}
#+RESULTS:
| Language                 | Mentions in this Document |
|--------------------------+---------------------------|
| Haskell                  |                        34 |
| C++                      |                        23 |
| D                        |                        22 |
| Rust                     |                        21 |
| Lisp, Racket, and Scheme |                        17 |
| Scala                    |                        13 |
| Java                     |                        11 |
| C#                       |                        10 |
| ML                       |                        10 |
| Idris                    |                         9 |
| C                        |                         6 |
| Python                   |                         5 |
| JavaScript               |                         4 |
| Kotlin                   |                         3 |
| Fortran                  |                         2 |
| BASIC                    |                         1 |
| COBOL                    |                         1 |
| Go                       |                         0 |


* Minimal Example

This section provides a quick introduction to the language in the form of a small ~ripl~ program that computes the factorial of 5, followed by a brief discussion:

#+LATEX: \begin{minipage}{\linewidth}
#+NAME: Factorial in ~ripl~
#+CAPTION: Factorial in ~ripl~
#+BEGIN_SRC racket
define (main) (factorial 5)

define (factorial (i32 n)) i32
  if (<= n 1)
    1
    * n (factorial (- n 1))
#+END_SRC
#+LATEX: \end{minipage}

Although small, this example demonstrates many of the language's defining characteristics:
1. ~ripl~'s syntax is expression oriented in that most of its syntactic constructs produce values rather than directing control flow (like Haskell, Lisp, ML, Rust, Scala, etc., and unlike C, C++, C#, Java, JavaScript, Python, etc.).
2. ~ripl~'s syntax is Lisp-like, and as such:
   1. Parentheses group expressions (expressions may also be grouped by whitespace, as described below).
   2. Names are separated by whitespace, parentheses, or one of a small number of reserved characters.
   3. Functions are applied by grouping as in Haskell, ML, and Lisp (i.e. ~(f x1 ... xn)~)[fn:1], as opposed to the traditional mathematical notation of languages with C-style syntax (i.e. ~f(x1, ... xn)~).
   4. The structure of the source code reflects the structure of the abstract syntax tree.
   5. Consequently, the language has no infix notation, operator precedence or associativity, an aspect of Lisp that is counter-intuitive for many (myself included), possibly because people are not accustomed to reading mathematical expressions without these conventions. ~ripl~ will ultimately have infix notation, though I'm presently considering two ways of doing this ~TODO: Link to section about this~.
3. ~ripl~'s syntax includes some extensions over traditional Lisp syntax, inspired by [[https://sourceforge.net/p/readable/wiki/Home/][Readable Lisp S-expressions]]:
   1. Two or more expressions on a line are grouped.
   2. Lines are extended to include all subsequent expressions at the next level of indentation.
4. ~ripl~ does not distinguish between functions and operators, and as such names can be composed of unicode characters, with the exception of unicode control characters and a small set of reserved characters.
5. ~ripl~ provides a number of built in forms (e.g. ~define~, ~if~), functions (e.g. ~*~, ~-~, ~<=~) and types (e.g. ~i32~)
6. The entry point of a program is a function called ~main~.
7. Type annotations are required for function parameters; most other types can be inferred.
8. Return type annotations are required for recursive functions.
9. Names may be referenced in source files before they are defined.

Hopefully this example has helped to provide you with an intuition for the language, the features of which are discussed in more depth in the following sections.

[fn:1] though in Haskell and ML expressions are often grouped by the parser rather than explicitly by parentheses


* Design Goals and Related Features

# In this section, really consider using a what, why, how kind of format.

Although I've heard it said that programming languages are "just tools", that any language can be "learned in a week", that the choice of language "doesn't matter" and that the differences between programming languages are superficial or primarily syntactic[fn:2], I think that the differences between languages are substantial and important. To quote Edsger Dijkstra, "the tools we are trying to use and the language or notation we are using to express or record our thoughts, are the major factors determining what we can think or express at all"[fn:3].


# Should the following go under the robust section?

Certain kinds of bugs, problems, and anti-patterns (such as null pointer exceptions, memory leaks, hidden side-effects, and shared or global mutable state), issues that can slow development, block teams, produce unpredictable programs, negatively impact users, and cost thousands of dollars, affect only some languages. Just as importantly, and as mentioned by Dijkstra, the ability to express certain thoughts and ideas is contingent on the features of the language in use.

One language that solves many of these problems, in addition to providing many expressive constructs, is Haskell, a language which ([[https://www.cs.utexas.edu/users/EWD/transcriptions/OtherDocs/Haskell.html][to quote Dijkstra again]]) "though not perfect, is of a quality that is several orders of magnitude higher than Java, which is a mess"[fn:5]. Before mentioning some criticisms of Haskell, it's worth mentioning that it feels like a very enlightening language, that operates in many ways at a higher level of abstraction than many other languages (with type classes in particular). Additionally, I find the libraries to be superb.

Unfortunately Haskell solves the problems posed by side-effects and mutability by confining them to specific monads (namely IO and ST). Although this achieves the aim of differentiating between pure and impure computations, and does so in an elegant way, the combined abstractions of lazy evaluation, implicit indirection, and monads make it much harder (in my experience[fn:8]) to optimize or reason about computationally intensive, highly stateful and highly interactive programs in Haskell than it is in other languages, especially languages that are designed for this purpose like C++ and Rust.

This is not to say that Haskell is not reasonably performant, because it is[fn:6], or that monads are not useful, because they are[fn:7], but rather that there are other ways to impose constraints on the mutability of data (as employed in C++, D, and Rust) and purity of functions (as employed in D), that do not require this additional level of complexity and abstraction. Similar methods are employed in ~ripl~ and are described in the following section.

# - The potential performance implications of purely functional programming go beyond just.
# - There are many advantages of purely functional linked lists,

# https://arxiv.org/pdf/1409.0252.pdf

# Things to clarify still in this section
# - Correlation found between imperative code and bugs, cite the study
# - Haskell is actually quite performant, cite the study
# - Monads have a variety of uses beyond modelling stateful computations

[fn:2] The people I've heard voice these opinions are all C++, C#, Java, or Python programmers, so maybe they just haven't experienced the full diversity of programming languages.

[fn:3] Edsger Dijkstra, EWD 340: The Humble Programmer, https://www.cs.utexas.edu/~EWD/transcriptions/EWD03xx/EWD340.html

[fn:5] Edsger Dijkstra, To the members of the Budget Council, https://www.cs.utexas.edu/users/EWD/transcriptions/OtherDocs/Haskell.html

[fn:8] ~TODO: Monads can make stateful computations harder to reason about~

[fn:7] ~TODO: Monads are useful~

[fn:6] ~TODO: Haskell reasonably performant~

** COMMENT Notes

# Can I tie this in with what Simon Peyton Jones is talking about with a future Haskell being strict?

# Consequently, the intent for this language is to be robust by obviating as many of these problems as possible, while remaining versatile

# Segue to Haskell, Djikstra's opinion of Haskell, quote about Haskell about making the easy things hard, address some of the challenges associated with it, as well as mentioning some of the problems it solves.

# Likewise, some languages simply do not have the capabilities of others, and though it may not be easily possible to measure or account for the impact of these differences, these differences persist.

# Haskell does an excellent job of preventing a wide range of bugs and sources of error. Unfortunately, it does so in some cases by sacrificing some capabilities, such as mutation,
# Haskell creator jokes about

# Although some developers I've spoken with are under the impression that programming languages are "just tools", that the choice of language "doesn't matter", and that the differences between programming languages are superficial or primarily syntactic, I think that the differences are substantial and important.

# Because certain kinds of bugs, problems and anti-patterns are only possible in certain languages, and because these issues can impede or block teams, thereby slowing development and wasting potentially thousands of dollars the choice of language is important.

# The following section provides an overview of ~ripl~'s design goals and the language features that are intended to achieve these goals.

# Games are often at the forefront of what hardware can do, and although it would be a very expensive experiment (to attempt to implement a state of the art 3d game or game engine in Haskell), I do not have confidence that Haskell would be as fit for this purpose as a language like C++ or Rust, though for many or most other purposes I think Haskell would be superior.


** Robust

*** COMMENT Notes

# TODO Should go somewhere:

# What's more, although Haskell's performance is legendary within the Haskell community, a third party comparative study of programming languages conducted by ETH Zuric found Haskell's performance to be average, and its memory usage to be the worst among any language considered (possibly as a result of laziness).

# Having worked in the games industry for 2.5 years, in a 20 year old and approximately 4 million line C++ codebase, I've observed some patterns that have given rise to some problems, many of which I feel can be attributed to the language itself:
# - Long compile times:
# - Null pointer exceptions: these can arise easily when there's uncertainty as to whether null is an acceptable value for a pointer
# - Singletons and side-effects:

# The problems mentioned above would not have been possible in Haskell.

# One thing I feel I can say about Haskell with little hesitation, is that it's a very robust language, and that many of the bugs and anti-patterns that I've encountered working in the games industry

# Having worked as a programmer in the games industry for 2.5 years, in a 20 year old, approximately 4 million line C++ codebase, a lot of the anti-patterns and bugs I encountered were related to imperative and object-oriented programming:

# In order to understand what is robust, it may be worth considering some bugs and anti-patterns found in the wild that are not robust.
# - Singletons:
# - Deep inheritance hierarchies:
# - Needless interfaces:
# - OOP insanity:
# -
# Weird OOP

# - Rampant/flagrant use of singletons that can make initialization, saving and loading almost impossible to understand.
# - A class hierarchy 6 levels deep, with virtual functions that branched on an internal type tag, so that in order to understand the behaviour of an instance you needed to consider the intersection between its subtype and type tag.
# - Implicit requirements on the state of the arguments.
# - Measurements of angle in different directions in different units.
# - Different coordinate systems used by different parts of the engine.


#  All of this for no discernible reason.
# - An interface with pure virtual functions called IFoo that was implemented Foo, and was also implemented by FooProxy which wrapped all methods of Foo.

# None of this would have been possible in a language like Haskell, and much less of it would have been possible in a language like Rust. Conversely, I think this would have been much worse in a language like Python without static typing.

# - A lot of the problems I've encountered and bugs I've seen as a programmer are akin to miscommunication
# - Encoding something in the type system is better than documentation, especially if the type system is well constructed
# - I would like this language to be as robust and rigorous or nearly so as Haskell without sacrificing on various other features.

# The language enables the programmer to establish a wide range of constraints in the type system, by means of the following features:
# - Strong, static typing
# - Type-safe discriminated unions
# - Type-level constraints on the mutability of data
# - Type-level constraints on the existence of data (null-safety)
# - Type-level constraints on the purity of functions
# - Parametric polymorphism via templates
# - Constraints on template parameters via type-classes/traits
# - Type-level programming via templates and compile-time function evaluation
# - The language will be memory-safe, though whether this is achieved via garbage collection or a Rust-style ownership system is yet to be determined.


*** =+= Static Typing

Static typing has a wide range of applications and advantages. It can catch errors earlier in the development process and nearer to the source than the corresponding runtime errors, can improve performance by informing optimizations and reducing the number of runtime checks because data types are known in advance, can be used to disambiguate names via overload resolution (as in C++, C#, D, Java, and Scala), can ensure that only certain functions have side effects (as in D and Haskell), can ensure that only certain aspects of certain variables can be modified (as in C++, D and Rust), and can be used as a basis for metaprogramming (as in C++, D and Haskell).

When combined with type inference, these advantages can be leveraged with little-to-no increase in program length or programmer effort. As such the primary motivation for ~ripl~ is to embrace static typing and to extend the range of invariants that can be encoded within the type system at compile time, so that the language can be used to develop robust programs with predictable behaviour at any scale.

# Although some statically-typed languages like C++ and Java are notoriously verbose and awkward, with concise and elegant, statically-typed languages like Haskell and Scala on offer, it's hard to understand the appeal of dynamic typing. The only case I can think of in which the flexibility of dynamic typing might be necessary is in enabling Lisp-style macros: a feature that is present only in a small minority of relatively unpopular dynamically typed languages, namely Lisp, Scheme and Racket.

# Why then, the popularity of dynamically typed languages like Python, JavaScript and PHP? I don't know, any more than I can explain the popularity of Java, C and C++.

# The only advantage I can think of that dynamic typing might provide, are the advantages that dynamic typing  confer to

# If the only statically typed languages on offer were verbose and unwieldy imperative languages like C++ and Java,
# Having used dynamically typed languages like Emacs Lisp, JavaScript, Python, R and Racket, I've never really understood the appeal of dynamic typing. If the only statically typed alternatives were verbose and unwieldy imperative languages like C++ and Java, then I might understand, but with concise and elegant functional languages like Haskell and Scala on offer,

# Having used dynamically typed languages like Emacs Lisp, JavaScript, Python, R and Racket, I've never really understood the appeal of dynamic typing. If the only statically typed alternatives were verbose and unwieldy imperative languages like C++ and Java, then I might understand, but with concise and elegant functional languages like Haskell and Scala on offer,
# Personally I am a strong proponent of static typing and don't really understand the appeal of dynamic typing.


*** =+= Type-Safe Discriminated Unions

Type-safe discriminated unions, or sum types, (as seen in Haskell, ML, Rust and Scala, among others) provide a very powerful and intuitive way of modelling polymorphic data and computations that may take one of a number of forms. Some examples in ~ripl~ are shown below:

#+LATEX: \begin{minipage}{\linewidth}
#+NAME: Discriminated Unions in ~ripl~
#+CAPTION: Discriminated Unions in ~ripl~
#+BEGIN_SRC racket
;; the union keyword can be used to create type-safe discriminated unions
union expression
  struct add (^expression a) (^expression b)
  struct sub (^expression a) (^expression b)
  struct mul (^expression a) (^expression b)
  struct div (^expression a) (^expression b)
  f32

;; it can be combined with the template keyword to create a parameterized union
template (list a)
  union
    struct nil
    struct non-empty
      a head
      ^(list a) tail
#+END_SRC
#+LATEX: \end{minipage}

Unlike untagged unions that do not record the type of the union's value, and non-type-safe discriminated unions in which a type tag is manually set and branched on by the programmer, type-safe discriminated unions include a type tag that is automatically set during construction and automatically branched on during pattern matching. An example of pattern matching in ~ripl~ can be seen in section [[=+= Pattern Matching]].

Although discriminated unions are analogous in some respects to OOP style inheritance subtyping (which can even be used as a basis for discriminated unions, as in Scala), I would argue that type-safe discriminated unions when used in conjunction with pattern matching, result in code that is more robust, precise, straightforward and less tightly coupled than OOP style inheritance. As such, discriminated unions are an important feature of ~ripl~'s design, the advantages of which are highlighted in the following section on null-safety, for which they provide an excellent solution.

# Discriminated unions are a powerful tool for authoring and composing data types, and are analogous in some respects to OOP style inheritance and subtyping (in Scala, for example, discriminated unions are created using inheritance). They provide a very powerful and intuitive way of modelling data and computations that may take one of a number of forms,


*** =+= Type-Level Constraints on Existence (null safety)

The ability to substitute ~null~, ~nil~, etc. for many or all values is a frequent source of ambiguity and error in many languages, including C, C++, C#, D, Java, JavaScript, Lisp, Python, and Scala.

The null reference was invented in 1965 by Tony Hoare, who later described it as a "billion-dollar mistake" when speaking at a software conference called QCon London in 2009[fn:10].

#+BEGIN_QUOTE
I call it my billion-dollar mistake. It was the invention of the null reference in 1965. At that time, I was designing the first comprehensive type system for references in an object oriented language (ALGOL W). My goal was to ensure that all use of references should be absolutely safe, with checking performed automatically by the compiler. But I couldn't resist the temptation to put in a null reference, simply because it was so easy to implement. This has led to innumerable errors, vulnerabilities, and system crashes, which have probably caused a billion dollars of pain and damage in the last forty years.
#+END_QUOTE

Although the unrestricted and potentially unsafe use of ~null~ is a significant problem, the ability to represent a value that may or may not exist remains highly important. To date I've encountered two viable mechanisms by which a language can express potentially non-existent values while maintaining null-safety:

1. *Dependent Typing:* dependent typing is a language feature in which the type of an expression may depend on its value. Kotlin employs a limited form of dependent typing to differentiate between nullable and non-nullable pointers at compile time, based on type annotations in addition to control flow[fn:11].

2. *Type-Safe Discriminated Unions:* discriminated unions, as discussed in section [[=+= Type-Safe Discriminated Unions]], provide a very robust and safe way of representing polymorphic types, and is employed by Haskell, ML, and Rust, among others, to represent potentially non-existent values in a type safe way[fn:12].

Between these options I prefer type-safe discriminated unions, because they're simpler than full-blown dependent typing (as seen in languages like Idris, which is roughly speaking a strictly evaluated and dependently typed Haskell), and because type-safe discriminated unions are much more widely applicable than the limited form of dependent typing seen in Kotlin. In support of this idea, Idris, which has both discriminated unions /and/ dependent typing, implements its ~Maybe~ type in terms of unions[fn:13]; ~ripl~ will do the same.

[fn:10] Tony Hoare, Null References: The Billion Dollar Mistake, https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare

[fn:11] Kotlin Language Reference, Null Safety, https://kotlinlang.org/docs/reference/null-safety.html

[fn:12] Although Scala has type safe discriminated unions and an option type, it is not null-safe. The following expression type checks correctly and produces a null pointer exception at runtime: ~Some(null) match { case Some(x) => x.toString; case _ => ""}~

[fn:13] Idris Standard Library, Maybe, https://github.com/idris-lang/Idris-dev/blob/master/libs/prelude/Prelude/Maybe.idr


*** COMMENT Type-Level Constraints on Mutability ~(this text should be somewhere else)~

Unconstrained or underconstrained mutability is problematic. The more state a program has, and the more widely this state can be modified, the harder it is to reason about. Fortunately, there are a number of ways in which programming languages can enable programmers to limit the amount and scope of a program's state:

# How much harder would math be if it was stateful and the meaning of operations was subject to change in real time? That is what imperative programming with shared mutable state is like.


*** =+= Temporary, Local Variables

Although a number of languages have had a shaky history with temporary, local variables (including BASIC, COBOL[fn:9] and Fortran[fn:14]), we are fortunate that temporary, local variables are ubiquitous in modern languages. The locality of these variables reduces the scope in which their state can be accessed, and their transience reduces the state of the program that would otherwise persist between function calls. All variables in ~ripl~ not declared at the top level are temporary and local.

[fn:9] http://www.jeromegarfunkel.com/authored/cobol_apology.htm
[fn:14] http://www.mathcs.emory.edu/~cheung/Courses/561/Syllabus/5-Fortran/scoping.html


*** =?= Encapsulation

Considered one of the defining features of object-oriented programming, encapsulation is another feature that helps to limit the scope of program state. Although I do not have concrete plans for encapsulation and access modifiers in ~ripl~, encapsulation warrants mentioning because it demonstrates that not only functional languages are concerned with limiting the scope of mutable state but also imperative and object-oriented languages.


*** =+= Expression Orientation

Expression orientation is a language feature that allows programmers to perform computations by composing expressions rather than directing control flow or mutating intermediary values. Expression orientation is a continuum, from assembly languages and compiler intermediary representations that are highly imperative, to imperative languages with both expressions and statements (like C++, C#, Java, etc.), to fully functional languages in which everything or nearly everything is an expression (like Haskell, Lisp, ML, Scala, etc.).

Expression orientation helps to reduce the statefullness of a program by reducing the number of variables in scope and reducing the need to mutate these variables. Everything in ~ripl~ that is not a top-level definition is an expression. Expression orientation is discussed from a usability perspective in section [[=+= Expression Oriented Syntax]].
# Provide a link to expression orientation section under concise/intuitive


*** =-= Monadic Statefullness and IO

One way of constraining mutation, as seen in Haskell and Idris, is to limit mutation to occurring within monads (namely IO and ST, in both Haskell and Idris):

#+BEGIN_QUOTE
Every function in Haskell is a function in the mathematical sense (i.e., "pure"). Even side-effecting IO operations are but a description of what to do, produced by pure code. There are no statements or instructions, only expressions which cannot mutate variables (local or global) nor access state like time or random numbers.[fn:15]
#+END_QUOTE

Although I agree with the designers of these languages that it's important to separate pure and impure code, and that the way they have modelled stateful computations within a purely functional language is elegant, in practice I find that this additional monadic abstraction can make stateful code significantly harder to write (especially when combined with laziness, as in Haskell).

For example, during the semantic phase of the ~ripl~ compiler, every expression is "reduced" to a value, a type, or a typed expression. Most expressions will depend on other definitions in the program, and these definitions can occur in any order. To deal with this, I reduce the abstract syntax tree lazily, and feed the result back into the ~reduce~ function (a process called "tying the knot") so that the type or value of each definition can be computed in terms of others. Although this works perfectly in many cases, in order to handle cyclic dependencies the computation must be stateful and track the definitions it has already visited so that it does not loop infinitely. After two weeks of trying to get this to work in Haskell with the ST monad, I tried it in Scala, got it to work in a single afternoon, and subsequently ported the entire compiler to Scala.

Although this anecdote does not demonstrate that the above problem could not be solved with laziness and monads in Haskell, or that this problem could not be solved without resorting to mutation at all, it is an example in which Haskell's approach to statefullness made a problem intractable for a user. While constraints on mutability and function purity are important, straightforward imperative/stateful programming is also valuable, and at times necessary. ~ripl~'s approach to encoding these constraints while preserving the ability to perform straightforward stateful programming is discussed in the following two sections: [[=+= Type-Level Constraints on Mutability]] and [[=+= Type-Level Constraints on Purity]].

[fn:15] Haskell Website, Purely Functional, https://www.haskell.org/


*** =+= Type-Level Constraints on Mutability

A middle ground between the unconstrained or under-constrained mutability and impurity of languages like C#, Java, ML, and Scala, and the functional purity of languages like Haskell and Idris, are per-variable type-level constraints on mutability, as seen in C++, D and Rust. This is a really great feature in my view, because it removes the ambiguity of what can be modified within what scope, while still allowing mutation where necessary.

In C++ and D, types can be made immutable using the ~const~ keyword, with some differences[fn:16]:
1. ~const~ in C++ can be bypassed using ~const_cast~ or ~mutable~, which undermines its legitimacy.
2. ~const~ in D applies recursively to all types that a composite type is composed of, a quality they refer to as transitive. This has the the disadvantage of reduces the range of types that can be expressed, and may force the use of entirely mutable types when only parts of these types need to be mutable. For example, a function that simulates interactions between entities might operate on an immutable list of references to mutable entities, thereby expressing its intent to modify the entities themselves, and not the container. Unfortunately, this distinction cannot be expressed with D's transitive ~const~.

In Rust, types can be made mutable using the ~mut~ keyword. The advantage of immutability by default, is that the keyword is /required/ to mutate a value; whereas in C++ and D data can be mutated or not mutated without the need to specify. Rust then uses this feature to prevents data races at compile time with the following rule: "At any given time, you can have /either/ one mutable reference /or/ any number of immutable references."[fn:17] Whether ~ripl~ can achieve the same in future will depend on a choice between garbage collection and a Rust-style ownership system, a decision that hasn't been made yet. Although a Rust-style ownership system has many advantages, I am uncertain about the complexity this might add to the language and how difficult this would be to implement.

The equivalent in ~ripl~ of Rust's ~mut~ keyword is the =~= symbol, which was chosen because:
1. It is not a commonly used symbol in programming.
2. It is shorter than ~mut~.
3. It looks fluid, hence changing, hence mutable.

The purpose of the mutable type modifier in ~ripl~ is to restrict mutation to a set of variables that are explicitly mutable within the present scope. Assignment between mutable and immutable values and references are handled according to the following table:

#+ATTR_LATEX: :placement [H] :align l|rlll :caption \caption{Assignment Between Mutable and Immutable Values and References} \rowcolors{1}{}{gray!15}
| Type  | Assign to =T= | Assign to =~T= | Assign to =^T=   | Assign to =^~T=  |
|-------+---------------+----------------+------------------+------------------|
| =T=   | value copied  | value copied   | value referenced | type error       |
| =~T=  | value copied  | value copied   | value referenced | value referenced |
| =^T=  | value copied  | value copied   | reference copied | type error       |
| =^~T= | value copied  | value copied   | reference copied | reference copied |

These rules can be applied recursively to composite types like functions and templates. For the purpose of type-checking, this boils down to the following rule: mutable references cannot be created to immutable data.

[fn:16] D Language, const(FAQ), https://dlang.org/articles/const-faq.html#cpp-const

[fn:17] https://doc.rust-lang.org/book/second-edition/ch04-02-references-and-borrowing.html#the-rules-of-references


**** COMMENT Code to demonstrate mutability

# #+BEGIN_EXPORT latex
# \begin{minipage}{\linewidth}
# #+END_EXPORT
# #+NAME: scale-vector-in-place
# #+CAPTION: scale vector in place
# #+BEGIN_SRC racket

# struct character
#   string name
#   i32 health
#   i32 stamina

# define default-stamina 100
# ;; define healthy-threshold 50

# ;; This compiles: it does not modify its immutable parameter
# define (is-tired (^entity e))
#   < e.stamina tired-threshold

# ;; This compiles: it mutates its mutable parameter
# define (restore-stamina (^~entity e) (i32 amount))
#   if (is-tired e) ; this is okay, â types T, T <: ~T

#   set e.stamina ( (+ e.stamina amount)

# ;; This does not compile: it attempts to mutate its immutable parameter
# define (is-healthy (^entity e))
#   set e.health (+ e.health 10) ; compile error: attempt to modify an immutable value

# ;; This does not compile: it attempts to mutate its immutable parameter
# define (is-woundend (^entity e))
#   recover-stamina e            ; compile error: type conflict between attempt to modify an immutable value

#   < e.stamina 50

# struct interval
#   f32 min
#   f32 max

# ;; This function compiles
# define (contains (^interval i) (f32 x))
#   <= i.min x i.max

# ;; This function does not compile: it attempts to modify an immutable value
# define (contains (^interval i) (f32 x))
#   set i.min x ; compile error: attempt to modify an immutable value

# struct rectangle
#   interval x
#   interval y

# ;; This function does not attempt to modify any immutable values, and so compiles
# define (contains (^rectangle r) (vector v))
#   and (contains r.x v.x) (contains r.y v.y)

# ;; This function attempts to modify an immutable value, and so does not compile
# define (contains (^rectangle r) (vector v))
#   set r.x.min r.x.max ; compile error: attempt to modify an immutable value

# define (clamp (interval i) (f32 x))

# ;; define (contains (rectangle r) (vector v))
# ;;   and (

# struct health
#   i32 cur
#   i32 max

# define (alive (entity e))

# ;; This function attempts to mutate an immutable value and so does not compile
# define (is-within-bounds (^player p) (^rectangle bounds))
#   set p.health (- p.health 10)

# ;; This function does not attempt to mutate an immutable object, and so compiles
# define (is-within-bounds (^player p) (^rectangle bounds))
#   and
#     (> p.x bounds.x-min)
#     (< p.x bounds.x-max)
#     (> p.y bounds.y-min)
#     (< p.y bounds.y-min)

#   inflict-damage c 100

# ;; This function attempts to mutate an immutable value and will not compile

# define (inflict-damage (^~character c) (i32 damage))
#   set c.health (- c.health damage)

# define (inflict-damage-if-out-of-bounds 

# define (clamp (f32 x) (f32 min) (f32 max))
#   cond
#     (< x min) min
#     (> x max) max
#     x

# define (clamp-in-place (^~f32 x) (f32 min) (f32 max))
#   set x (clamp x min max)

# define (contains (^rectangle rect) 

# define (scale-in-place (^~vector v) (f32 a))
#   set v.x (* v.x a)
#   set v.y (* v.y a)

# #+END_SRC
# #+BEGIN_EXPORT latex
# \end{minipage}
# #+END_EXPORT


*** =+= Type-Level Constraints on Purity

# Should this be type-level constraints on impurity?

**** Discussion of Purity
An impure function is one that depends on or modifies global, mutable state like global variables and singletons, or performs system-level IO like interacting with the file-system, performing textual IO, invoking other processes or drawing to the screen. Although this IO is the purpose for which we create programs, there are some disadvantages to impure, or potentially impure[fn:18] functions, including:

1. Their behaviour may depend on global, mutable state.
2. Their inputs and dependencies may not be clear from their signature.
3. Their outputs and effects may not be clear from their signature.

Indeed, in order to /know/ how such potentially impure functions may interact with the program, it is necessary to recursively read all of the functions they call, and understand how all of these functions effect and are effected by the global state of the program, in addition to the feedback between them. In a suitably large and impure program, this complexity is not possible to comprehend. In a suitably large and impure program, the programmer may arrange functions to produce the desired effect in one place and break something somewhere else in the process. For these reasons, impure or potentially impure functions are harder to test, harder to debug and harder to reason about.

At its most extreme, systemic impurity entirely subverts the purpose of function signatures in documenting what functions do, and thereby undermines the structure of the program. When a language fails to distinguish (as most do) between the signature of the entry point of the program (something like =int main()=), a function that can do /anything/, and the signature of a pure function like addition (something like =int +(int, int)=), how can any function in this language be trusted?

In a purely functional program you can tell how the pieces fit together from their types, whereas in a more imperative program there may be a way to arrange and order the pieces such that they fit, but it may not be immediately obvious how. In a pure language like Haskell, we know a lot about a function with a type like =A -> B=. We know that it will use an =A= to compute a =B= without depending on or modifying the state of the program in any way[fn:19], and consequently that:
1. It always produces the same output given the same input.
2. It does not effect the program and so can be called any number of times without consequence.
3. It behaves the same way within the context of the program as it does when tested in isolation.
4. It can be evaluated at compile time if its arguments are known at compile time.

Even if a function performs computations with mutable state internally, as long as these internal mutations do not escape to the outside world, all of the above properties still hold. In pure functional languages like Haskell and Idris, this encapsulation of effects and separation of pure and impure code is done using monads (such as IO and ST), as discussed in section [[=-= Monadic Statefullness and IO]]. As mentioned in that section, I think this encapsulation of effects is positive, but I have concerns about the complexity of this approach, both for the programmer and for the machine.

**** Purity in D
A solution to this problem in an impure language can be found in D, and is described quite well by David Nadlinger[fn:20]. D allows functions to be annotated using a ~pure~ keyword, which prevents them from performing impure computations or calling other impure functions. Combined with compile-time evaluation of pure functions and templates that can take values of any type arguments, this feature provide a basis for powerful type-level programming and type-level constraints on purity in D.

**** Purity in =ripl=
~ripl~'s method of constraining purity is similar to that of D, but differs in some respects. Rather than using a modifier keyword like D, ~ripl~ has a global state parameter =@=, that may be taken as a parameter to =main= and distributed to the rest of the program as an argument to other functions. In order to read global state (such as reading global variables, reading files, checking the current time, or using memory addresses in computations) functions must take =@= as a parameter. In order to modify global state (such as writing global variables, writing files, or writing to the console) functions must take =~@= as a parameter. =~@= may be substituted for =@= just as =^~T= may be substituted for =^T= as described in section [[=+= Type-Level Constraints on Mutability]]. The advantages of this approach include:
1. It leverages the same syntax and scoping rules as function parameters, so should be intuitive.
2. It is easily and intuitively encoded in function types, e.g. =main= may have type =(-> ~@ i32)=.
3. Function purity is visible at the call site in addition to the signature (e.g. =println ~@ "Hello world!"=).
4. It's possible to express the difference between read-only impurity =@= and read-write impurity =~@=.

# Maybe add something about how pure by default is better

Below is a table comparing pure and impure function signatures in various languages. Of the languages considered, D, Haskell and ~ripl~ are able to express the difference between pure and impure functions and C++ and Rust are not. The ability to express this difference is actually quite rare among languages, and the only others that I know of in which this is possible to express are purely functional languages like Idris, Clean and Frege. ~ripl~ is the only language I know of that uses a global state parameter, and can express the difference between read-only and read-write impurity.

#+LATEX: \begin{table}[htbp]
#+LATEX: \caption{Comparison of Pure and Impure Function Signatures in Various Languages}
#+LATEX: \adjustbox{max width=\linewidth}{
#+LATEX: \rowcolors{1}{}{gray!15}
| Language | Potentially Impure | Pure with Mutable Arguments         | Pure                                  |
|----------+--------------------+-------------------------------------+---------------------------------------|
| C++      | =int main()=       | =void normalize(Vector& v)=         | =Point operator+(Point a, Point b)=   |
| D        | =int main()=       | =pure void normalize(ref Vector v)= | =pure Point add(Point a, Point b)=    |
| Haskell  | =main :: IO ()=    | =normalize :: Vector -> Vector=     | =(+) :: Point -> Point -> Point=      |
| ~ripl~   | =(main ~@)=        | =(normalize (^~Vector v))=          | =(+ (Point a) (Point b)) Point=       |
| Rust     | =fn main()=        | =fn normalize(v: &mut Vector)=      | =fn add(a: Point, b: Point) -> Point= |
#+LATEX: }
#+LATEX: \end{table}

A ~ripl~ function that does not take the global state parameter, but takes one or more mutable references is weakly pure; a ~ripl~ function that takes neither the global state parameter, nor any mutable reference is strongly pure[fn:24]. In addition to aiding the creation of robust programs as described throughout this section, this type-level information on function purity will help the ~ripl~ compiler determine what functions can be evaluated at compile time (as described in [[=+= Compile-Time Evaluation]]), and may useful in directing optimizations in future.

# TODO Of course, every useful program needs to perform effects, talk about three layer cake, onion architecture, thin layer of IO on top of functionally pure business logic.

# I once created an alternate initialization path for a 20 year old and approximately 4 million line C++ game engine with a diverse cast of singletons and little-to-no documentation. It was a two week process of cutting, pasting, adapting, reordering and binary searching.

[fn:18] The purity of a function in a language that does not distinguish between pure and impure functions can only be determined by recursively reading it and all of the functions it calls, which may not be feasible.

[fn:19] Unless it circumvents the type system by some mechanism like Haskell's =unsafePerformIO=, but this is uncommon.

[fn:20] David Nadlinger, Purity in D, http://klickverbot.at/blog/2012/05/purity-in-d/

[fn:21] Creating new data is as close as we get to modifying data in place in Haskell, without resorting to ST monad which would be overkill in this case.

[fn:24] This terminology is used by, and possibly introduced by, the D programming language:
https://tour.dlang.org/tour/en/gems/functional-programming


*** =+= Namespaces

Although they are referred to by many names (packages, modules, namespaces, and possibly others), and there are a lot of variations in their behaviour between languages, namespaces are essentially a system to restrict the visibility of names and avoid name collisions. This is important, and prevents the need to prefix every symbol name with the library that it comes from, as may be necessary in languages without this feature like C and some Lisps. ~ripl~'s namespace feature is inspired by and very similar to that of C#. In addition to this system, which is pretty simple, I would like to add a feature that will allow the compiler to infer namespaces from the directory structure, to reduce the potential for inconsistency between the namespace structure and directory structure of a project.


*** =?= Garbage Collection

Although garbage collection is the norm among most high-level programming languages, and memory safety is a major advantage, there are some disadvantages to garbage collection:

1. Garbage collection may result in unexpected pauses which may not be suitable for real time and soft real time applications.
2. Non-deterministic garbage collection prevents the use of destructors for deterministic resource disposal (a pattern called RAII), which is a useful pattern for managing both memory and other resources.

Because ~ripl~ already has a number of things in common with Rust, like mutability modifiers and explicit indirection, I am inclined to try a Rust style ownership system, and will fall back on garbage collection if an ownership system does not work out well.


** Performant

As a statically-typed and compiled language with mutable data-structures, and without virtual functions, lazy evaluation, or implicit indirection (e.g. boxing), ~ripl~ is susceptible to a similar range of optimizations as languages like C++ and Rust. By using LLVM-IR as a compile target, as does the Rust compiler rustc, and C++ compiler Clang, ~ripl~ can leverage many of the same optimizations. If ~ripl~ adopts an ownership system inspired by Rust instead of garbage collection (a decision that is discussed in [[=?= Garbage Collection]]), then ~ripl~ may have similar performance potential to C++ and Rust (though actual performance will depend on the implementation).


** Ergonomic, Intuitive, and Concise

In order for a language to be enjoyable to use (or at least unobtrusive), it needs to be ergonomic, intuitive and concise. Although some people don't seem to take syntax very seriously (by dismissing it as superficial bike-shedding, describing it as a "solved problem", or wondering why discontent users of verbose languages are "afraid of typing"), I'm inclined to agree with Simon Peyton Jones, when he wrote in a presentation about Haskell's design[fn:22]:

#+BEGIN_QUOTE
+Syntax is not important+

Syntax is the user interface of a language

+Parsing is the easy bit of a compiler+

The parser is often the trickiest bit of a compiler
#+END_QUOTE

Although some syntax elements may be a matter of preference, there is one very large and measurable differences between various languages' syntaxes: verbosity. A study by Sebastian Nanz and Carlo A. Furia of ETH Zurich, of programs in Rosetta Code (a repository of solutions to over 700 programming tasks in hundreds of languages), found that[fn:23]:

#+BEGIN_QUOTE
Languages are clearly divided into two groups: functional and scripting languages tend to provide the most concise code, whereas procedural and object-oriented languages are significantly more verbose. The absolute difference between the two groups is major; for instance, Java programs are on average 2.2â2.9 times longer than programs in functional and scripting languages.
#+END_QUOTE

While these findings are consistent with my own experiences, their magnitude exceeds my expectations (and validates my frustraion with certain verbose languages). Among the largest effects in their study, they found that, of the programs in their data set, programs in C# were on average 2.7 times as long as programs in Haskell and 3.6 times as long as programs in Python.

Although I've heard apologists of verbose languages defend their verbosity by insisting that code is read more often than it is written, code that is 2-3 times longer is longer both to read and write. This is not to say that more concise is always better (adequately descriptive names are good), but I do not think that C++, C#, D, Java, etc. have gained any clarity in their verbosity: instead I think bugs lurk in their boilerplate.

*** Brief History of =ripl='s Syntax

As the user interface of a language (per Simon Peyton Jones[fn:22]), syntax warrants serious care and consideration. Nearly all aspects of ~ripl~'s syntax have changed radically over the course of its history thus far. This has been part of an ongoing process of development and, I hope, improvement.

Following its inception in February 2017, ~ripl~'s syntax was a [[https://github.com/SongWithoutWords/pidgin/blob/78205a910516c1defb62344e74a271cef4675a49/src/Parser.y][Python-like BNF grammar]] with C-style function application and whitespace delimited blocks. It had both statements and expressions, and both if-expressions and if-statements (also like Python). As time went on, I started to think that this distinction between statements and expressions was redundant and inelegant. In a commit in January 2018, [[https://github.com/SongWithoutWords/pidgin/commit/51804e611d0d394a6f388b5b15e9f9bbd4ebcfcc][statements were removed from the grammar,]] and the language started to become expression oriented. By early June 2018, [[https://github.com/SongWithoutWords/ripl/blob/87b64d2ded8a0c88180e7fef701bb9015df46c7b/src/main/antlr4/RiplParser.g4][nearly all constructs had become expressions in the grammar]], including composite types like structs, unions, and function types.

In mid-June 2018, I came across [[https://sourceforge.net/p/readable/wiki/Home/][Readable Lisp S-expressions]][fn:4], and was very impressed by this notation, which combines the simplicity, elegance, generality, and homoiconicity (self-representing nature) of Lisp's S-expressions with the brevity and legibility of whitespace delimitation. I immediately set about changing ~ripl~ to use this new syntax (examples of which can be seen in [[Minimal Example]] and [[=+= Type-Safe Discriminated Unions]]).

At the time of writing I have not yet ported all constructs from the old Python-like grammar to the new Lisp-inspired grammar. For example, I do not yet know what the syntax will be for multi-expression blocks, though it may be something like this:

#+LATEX: \begin{minipage}{\linewidth}
#+NAME: Multi-Expression Blocks in ~ripl~
#+CAPTION: Multi-Expression Blocks in ~ripl~
#+BEGIN_SRC racket
define (power-of-8 (f32 x1))
  block
    let x2 (* x1 x1)
    let x4 (* x2 x2)
    * x4 x4
#+END_SRC
#+LATEX: \end{minipage}

# TODO: Rest

[fn:22] Simon Peyton Jones, Wearing the Hair Shirt: A Retrospective on Haskell, slide 9,
http://www.cs.nott.ac.uk/~pszgmh/appsem-slides/peytonjones.ppt?ref=driverlayer.com/web

[fn:23] Sebastian Nanz, Carlo A. Furia, A Comparative Study of Programming Languages in Rosetta Code, page 6,
https://arxiv.org/pdf/1409.0252.pdf


*** COMMENT Notes

# Before we get into the specifics of how ~ripl~'s design endeavours to achieve these goals, it may be worth discussing other languages from this perspective:
# - *C++*
# - *D*
#   - ~Pro~ compile-time function evaluation is a good alternative to template meta-programming.
# - *Haskell*
#   - ~Pro~
#   - ~Con~ lack of name overloading
#   - ~Con~ poor module system
# - *Idris*
# - *Lisp*

# Having worked full time doing game programming in C++ for 2.5 years, and having written in more ergonomic languages like  do not believe it met these goals.

# By emulating certain features of concise languages, like Haskell, Racket and Scala, it is hoped that this language can be made concise as well. What sets these languages apart from other more verbose languages?

# Some languages are more ergonomic, concise and intuitive than others. Having worked for 2.5 years in C++, I'm fairly confident in the assertion that it is more verbose than Python. After translating an ~2000 line program at a job from Python to Scala, I found the Scala version to be ~20% shorter (in addition to being statically typed). After porting a complete set of LLVM bindings (llvm-hs) from Haskell to Scala (for this project), I found the Haskell version to be ~20% shorter as well.

# After 2.5 years working full time in C++, for example, I would place this language at the bottom of this spectrum. Slightly better, I would suggest, are languages like C# and Python.
# - Type inference
# - Subtyping via implicit conversions
# - Name overloading
# - Expression oriented
# - Pattern matching
# - Readable, uniform syntax, inspired by [[https://sourceforge.net/p/readable/wiki/Home/][Readable Lisp S-expressions]]


*** =+= Whitespace Delimitation

Although indentation delimited languages are somewhat uncommon, people speak highly of them (e.g. Haskell and Python). I am a proponent of this style for a number of reasons:
1. Even without whitespace delimitation, people rely on indentation to read code, because it's very hard to read without[fn:25]. Why not leverage this visual structure?
2. It reduces the number of tokens and visual clutter.
3. It ends any discussion or inconsistency over whether opening braces should occur on a new line.
4. It reduces the potential for inconsistency between the visual and the semantic structure of the code, thereby reducing the potential for error and confusion.

For these reasons, expressions in ~ripl~ /may/ be grouped by indentation. It is, however, possible to write ~ripl~ code that is explicitly delimited[fn:28], because indent and dedent expressions are not emitted within S-expressions.

[fn:25] Richard J. Miara et al, Program Indentation and Comprehensibility,
https://www.cs.umd.edu/~ben/papers/Miara1983Program.pdf

[fn:28] The only reasons I can think of for doing so would be to embed ~ripl~ code within some other data format, to serialize it more compactly, or to operate on it with tools that are designed to work with S-expressions.


*** =+= Type Inference

Type inference makes it possible to omit some or all type annotations while maintaining the benefits of static typing. Broadly speaking, there are two styles of type inference: Hindley-Milner or full type inference and bidirectional or partial type inference. Hindley-Milner style type inference has the advantage that it can infer the types of /all/ expressions within the program, including function parameters.

However, the syntactical unification algorithm often used for Hindley-Milner type inference[fn:29] is complicated by the presence of overloading. Furthermore, it breaks down in the presence of subtyping[fn:26] because the type constraints generated from the program no longer constitute a system of type equations that can be solved via substitution, but rather a system of subtyping relationships that are non-strict type inequalities (=T1 <: T2= being analogous to ~a <= b~).

Although alternative algorithms have been developed to support Hindley-Milner style type inference with subtyping[fn:27]\textsuperscript{,} [fn:30], ~ripl~ is proceding with bidirectional type inference for the following reasons:
1. Because supplying type annotations for function parameters is not so burdensome, and is even considered good practice in languages like Haskell in which these types can be inferred.
2. Because bidirectional subtyping operates on the level of expressions rather than type constraints, it's relatively easy to combine with compile time evaluation, another desired feature of ~ripl~ (see section [[=+= Compile-Time Evaluation]])

In summary, ~ripl~ trades full type inference (that could infer parameters types) for overloading, subtyping, type classes, and compile time evaluation.

[fn:26] ~ripl~ began without subtyping or overloading and used constraint generation and the unification algorithm for type inference. When I added overloading to ~ripl~, I continued to use the unification algorithm by deferring the unification of constraints with overloads until the types of the overloads and the types of the arguments were known. When I then added subtyping to the language it became clear that unification would no longer work, and I reverted to bidirectional type checking.

[fn:29] Cornell University, CS3110, Type Inference and Unification,
http://www.cs.cornell.edu/courses/cs3110/2011fa/supplemental/lec26-type-inference/type-inference.htm#3

[fn:27] Dmitriy Traytel, Stefan Berghofer, and Tobias Nipkow, Extending Hindley-Milner Type Inference with Coercive Structural Subtyping,
https://www21.in.tum.de/~nipkow/pubs/aplas11.pdf

[fn:30] Stephen Dolan, Algebraic Subtyping, https://www.cl.cam.ac.uk/~sd601/thesis.pdf


*** =+= Subtyping via Implicit Conversion

Subtyping is a common feature among object-oriented programming languages. It is much less common among functional languages, possibly because of the complexity it adds to type inference, as discussed in section  [[=+= Type Inference]]. Although it is less essential in a language without inheritance (like ~ripl~), subtyping helps to reduce the need for explicit type conversions.

Although subtyping and implicit conversion have somewhat of a bad reputation[fn:32], I think that implicit conversions can still add value if chosen judiciously. Subtyping in ~ripl~ is achieved via implicit conversions. The ~ripl~ compiler provides a built-in conversions from integral numbers to floating point numbers, and may in future provide implicit conversions from the variants of a union to the union itself. Additionally, the compiler is structured to allow for user-defined implicit conversions. Although the syntax for declaring user-defined implicit conversions has not yet been chosen, it will probably consist of defining a pure function with a single input using a distinct keyword like ~implicit~ instead of the usual ~define~ keyword. An example of subtyping in ~ripl~ is given below:

#+LATEX: \begin{minipage}{\linewidth}
#+NAME: Subtyping via Implicit Conversion in ~ripl~
#+CAPTION: Subtyping via Implicit Conversion in ~ripl~
#+BEGIN_SRC racket
define (add-int-and-float (i32 x) (f32 y))
  ;; The only viable overload is (+ f32 f32), and so x is implicitly converted
  + x y
#+END_SRC
#+LATEX: \end{minipage}

The rules used for the selection of overloads in the presence of implicit conversions are described in [[=+= Name Overloading]].

[fn:32] This is especially true in languages like C, in which widespread and questionable implicit conversions allows some types to be used almost interchangeably that should not be, like booleans, integers, and pointers.


*** =+= Expression Oriented Syntax

Expression orientation is discussed within the context of the Robust design goal in section [[=+= Expression Orientation]], because it enables programming with fewer local variables thereby reducing statefullness within functions. Within the context of usability, I think that expression orientation lends itself to a more composable, ergonomic, elegant, and concise programming style. I would not be surprised if the tendency against expression orientation among imperative languages accounts for some of the verbosity of these languages that was found by Nanz and Furia [fn:23]. Everything in ~ripl~ that is not a top-level definition is an expression.


*** =+= Pattern Matching

Discriminated unions are a feature of ~ripl~ that is discussed in section [[=+= Type-Safe Discriminated Unions]]. Pattern matching is essentially a type-safe and ergonomic method of extracting information from discriminated unions that contain one of a number of types, and works behind the scenes by branching on type tags. In addition to type safety, pattern matching has the advantage that the structure of the data being matched tends to be very evident from the code. Below is an example of pattern matching in ~ripl~ used to write a simple evaluator for some floating point expressions:

#+LATEX: \begin{minipage}{\linewidth}
#+NAME: Pattern Matching in ~ripl~
#+CAPTION: Pattern Matching in ~ripl~
#+BEGIN_SRC racket
;; the union keyword can be used to create type-safe discriminated unions
union expression
  struct add (^expression a) (^expression b)
  struct sub (^expression a) (^expression b)
  struct mul (^expression a) (^expression b)
  struct div (^expression a) (^expression b)
  f32

define (evaluate (^expression e))
  ;; the match keyword can be used to operate on unions
  match e
    (add a b) (+ (evaluate a) (evaluate b))
    (sub a b) (- (evaluate a) (evaluate b))
    (mul a b) (* (evaluate a) (evaluate b))
    (div a b) (/ (evaluate a) (evaluate b))
    (f32 val) val
#+END_SRC
#+LATEX: \end{minipage}


*** =?= Infix Notation and Word Order

Word order (including subject-object-verb or SOV, subject-verb-object or SVO, and verb-subject-object or VSO) is a characteristic of the grammar of both human and programming languages, some aspects of which are summarised in the table below.

#+ATTR_LATEX: :placement [H] :align l|rlll :caption \caption{Word Order in Human and Programming Languages} \rowcolors{1}{}{gray!15}
|     | Percent of Human Population[fn:34] | Example Languages[fn:38] | Programming Constructs  | Example Code        |
|-----+------------------------------------+--------------------------+-------------------------+---------------------|
| SOV |                                45% | Farsi, Hindi             | Reverse Polish notation | =map key contains=  |
| SVO |                                42% | English, Mandarin        | Methods in OOP          | =map.contains(key)= |
| VSO |                                 9% | Arabic, Hebrew           | Traditional functions   | =contains map key=  |
| VOS |                                 3% | Baure, Malagasy          | Traditional functions   | =contains key map=  |

Some studies have found that people tend naturally to use subject-verb-object order when communicating with an established lexicon (even when they are accustomed to another order)[fn:39], and that people tend naturally to use subject-object-verb order when communicating with an improvised lexicon (even when they are accustomed to another order)[fn:40]. Combined with the relative unpopularity of verb-first word orders in human languages, the findings of these studies may suggest that verb-first word orders are less suited to human comprehension, and may even explain some of the popularity of object oriented languages (which allow subject-object-verb order by means of method syntax) and unpopularity of Lisps (which typically do not even allow infix notation).

In addition to word order, many programming languages include infix notation with precedence and associativity (as used in conventional mathematical notation), which, like the method syntax of object-oriented languages, allows some or all verbs to appear in infix position, as in SVO ordering. Although I find it quite convenient to add terms by writing =(+ a b c d)= (as opposed to =(a + b + c + d)=), or to determine if terms are ordered a certain way by writing =(< a b c d)= (as opposed to =(a < b && b < c && c < d)=), programming languages with only function application and without infix notation or method syntax (notably Lisps) are often said to be unintuitive or hard to read (although I've been unnable to find any rigorous investigation of this).

Together these observations pose a number of questions:
1. How much influence does word order have on people's comprehension of programming languages?
   1. If this influence is significant, to what degree does it depend on the word order people are accustomed to?
   2. If this influence is significant, can it be overcome by continued use, or are some word orders inherently advantageous?
2. How much influence does the presence of infix operators have on people's comprehension of programming languages?
   1. If this influence is significant, can it be overcome by continued use, or is infix notation inherently advantageous?

If allowing infix and subject-verb-object ordering is desirable (of which I'm still not entirely convinced) there are a number of ways in which this could be achieved in ~ripl~:

1. Surround infix expressions in braces as proposed by Readable Lisp S-expressions[fn:4]. \newline For example ={a + b + c}= would be equivalent to =(+ a b c)=.
2. Typecheck both orderings of the first two expressions of all s-expressions; if the result of typechecking the s-expression with the order of the first two expressions reversed is better (i.e. fewer errors and implicit conversions), then use this order.

Because this is a rather complicated topic, and because either of the potential solutions mentioned above could be easily added, I am inclined to leave these features out for the time being, and add them in future if their absence is felt.


[fn:34] Russell S. Tomlin, Basic word order. Functional principles. London: Croom Helm, 1986. Page 308, \newline
https://www.cambridge.org/core/journals/journal-of-linguistics/article/russell-s-tomlin-basic-word-order-functional-principles-london-croom-helm-1986-pp-308/7542AFB4A8B28D651F6E109B810F4C04


[fn:38] Wikipedia, Subject-verb-object, https://en.wikipedia.org/wiki/Subject%E2%80%93verb%E2%80%93object


[fn:39] Alan Langus, Marina Nespor, Cognitive systems struggling for word order, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4534792/


[fn:40] Hannah Maro, Alan Langus, et al, A new perspective on word order preferences: the availability of a lexicon triggers the use of SVO word order, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4534792/#B23

# Although I came across this blog after writing this section, this subject has been written about before: https://solsort.com/2015/11/14/word-order-in-programming-and-human-languages/

# [fn:35] I used a programmable calculator (the HP 50g) in second year that used reverse Polish notation (e.g. =a b +=), which I found to be quite unintuitive, and some programming languages (notably Forth) use this ordering as well, which roughly corresponds to SOV ordering.

**** COMMENT Some code exploring syntactic differences between C-style expressions and Lisp

#+BEGIN_SRC C++
Array2D<Vector2> SobelFilter(const Array2D<float>& input)
{
  const size_t width = input.GetWidth();
  const size_t height = input.GetHeight();

  if (width <= 1 || height <= 1)
  {
    return {}; // return with default constructor
  }

  const size_t widthLessOne = width - 1;
  const size_t heightLessOne = height - 1;

  Array2D<Vector2> result{ width, height };
  for (size_t y = 1; y < heightLessOne; ++y)
  {
    for (size_t x = 1; x < widthLessOne; ++x)
    {
      y0x0 = input.Get(x - 1, y - 1);
      y0x1 = input.Get(x - 1, y - 1);

      dx = (y0x0 + 2 * y1x0 + y2x0)
         - (y0x2 + 2 * y1x2 + y2x2);

    }
  }
  return result;
}
#+END_SRC


#+BEGIN_SRC racket
let dx
  -
    + y0x0 (* 2 y1x0) y2x0
    + y0x2 (* 2 y1x2) y2x2
#+END_SRC

#+BEGIN_SRC racket
(let dx
  (-
    (+ y0x0 (* 2 y1x0) y2x0)
    (+ y0x2 (* 2 y1x2) y2x2)))
#+END_SRC


*** =+= Selection Syntax

Somewhat related to word-order (as discussed in section [[=?= Infix Notation and Word Order]]) is selection syntax. The idea is to allow =a.b= as a left-associative shorthand for =(b a)=, so that it's possible to write things like =(math.bits.xor a b)= instead of =((xor (bits math)) a b)=, or =(- character.transform.position camera.transform.position)= instead of =(- (position (transform character)) (position (transform camera)))=. In the examples above, I find the expressions with selection syntax clearer and more readable.


*** =+= Name Overloading

Overloading is a feature that is more noticeable when absent than present. In Haskell, for example, (which lacks traditional overloading) you cannot have two functions with the same name (including simple accessors like =name= or =size=) without creating a type class that declares the function, and then implementing the type class for all required types. As such, name collisions in Haskell can be avoided either by using type classes (which introduces a fair amount of boilerplate), or by modifying the function's name to reflect the type of its parameters. This absence of traditional overloading is clumsy, and has made Haskell's standard prelude inconvenient to use in a number of ways:
1. The standard prelude defines =id= as the identity function, so the name =id= cannot be used for variables that represent numeric identifiers (a common convention).
2. The standard prelude defines =map= on lists, so the more general operation of mapping over functors (including lists) needed to be called something else, and was caled =fmap=.
3. Because many collections, such as =Map= and =Set=, have operations with the same name, such as =size=, =null=, and =empty=, it's often necessary to import these modules qualified to avoid name collisions, in which case their contents must be referred to by a qualified name, such as =Set.size mySet= or =Map.size myMap=.
4. Because the =Num= type classes in Haskell's standard prelude declares =+=, =-=, =*=, and the =Fractional= type class extends the =Num= type class with =/= (among other operations)[fn:37], any type for which these operations are defined must implement all of the operations declared by these type classes. The way that these operations are defined, in addition to some of the other operations declared by these type classes, do not make sense for vector math, and so use of these symbols for vector math is incompatible with Haskell's standard prelude.

Although the problems mentioned above can be circumvented using an alternate prelude[fn:36], these problems are a symptom of the absence of overloading combined with a lack of foresight. The lack of overloading is inconvenient enough that there are a number of proposals within the Haskell community to fix it[fn:35]. In order to avoid these same problems, ~ripl~ supports overloading, according to the following rules:
1. When an overloaded name is type checked, each potential definition is type checked within its context.
2. The overloads are then sorted in ascending order, first by the number of errors, and then by the number of implicit conversions they produce within this context.
3. The first (best) overload is chosen.
4. If there is a tie for first place, then the overload is ambiguous and an error is raised.


[fn:37] http://hackage.haskell.org/package/base-4.11.1.0/docs/Prelude.html#g:7

[fn:36]http://hackage.haskell.org/package/classy-prelude, \newline
https://github.com/sdiehl/protolude

[fn:35] https://wiki.haskell.org/TypeDirectedNameResolution, \newline
https://ghc.haskell.org/trac/ghc/wiki/SyntaxFreeTypeDirectedNameResolution


*** =+= Simple and General Design

It's not uncommon in my experience that people (myself included) conceive of and solve problems at a lower level of generality and abstraction than possible. When this occurs in programming language design, it may introduce unnecessary complexity or limitation to the language. Some examples of this include:

1. Needless grammatical distinction between statements and expressions.
2. Needless grammatical distinction between types and expressions.
3. Needless distinction between invocations of non-virtual member methods and regular functions (solved either by universal function call syntax, as in D, or by not having methods, as in Haskell, ML, ~ripl~, Rust).
4. Needless distinction between array access notation and function application.
5. Needless distinction between functions and operators (solved either by allowing all functions to be invoked normally or in infix, as in Haskell and Scala, or by not having infix notation as in Lisp).

Below is a table that compares various classes of features that can be used to accomplish the same goal in C++ and ~ripl~, which demonstrates that languages can vary pretty widely in terms of complexity:

#+ATTR_LATEX: :caption \caption{Comparison of Various Constructs in \texttt{ripl} and C++} \rowcolors{1}{}{gray!15}
| Feature           | ~ripl~           | C++                                                                |
|-------------------+------------------+--------------------------------------------------------------------|
| Code organization | Namespaces       | Headers, namespaces, and modules (expected in C++20[fn:31])        |
| Conditions        | ~if~             | ~if~ statements and ternary expressions                            |
| Enumerations      | ~union~          | ~enum~ and ~enum class~                                            |
| Functions         | Functions        | Functions and methods                                              |
| Indirection       | References       | Pointers and references                                            |
| Initialization    | ~define a (A b)~ | ~A a(b)~, ~A a{b}~, ~A a = {b}~, and ~A a = A(b)~                  |
| Iteration         | Recursion        | ~for~, range-based ~for~, ~while~, ~do...while~, and recursion     |
| Metaprogramming   | Templates        | Templates and textual macros                                       |
| Printing          | ~println~        | C-style ~printf~ and C++ style IO streams                          |
| Record types      | ~struct~         | ~class~ and ~struct~                                               |
| Strings           | ~string~         | ~char[MAX_PATH]~, ~char*~, ~wchar*~, ~std::string~, ~std::wstring~ |
| Type conversions  | Functions        | C-style, dynamic, reinterpret, static, and const casts[fn:33]      |
| Type-aliases      | ~define~         | ~typedef~ and ~using~                                              |
| Unions            | ~union~          | ~union~ and ~std::variant~                                         |

By adopting more general solutions I think it's possible to reduce the complexity of a language. This is one of ~ripl~'s goals, and its design should be continually revised as new opportunities for generalization are discovered. If the language gets a user base in future this could be done with non-backwards compatible major versions whenever a suitable number of potential improvements have been identified.

[fn:31] Dmitry Guzeev, A Few Words on C++ Modules,\newline
https://medium.com/@wrongway4you/brief-article-on-c-modules-f58287a6c64

[fn:33] These casts are not functions but language level features,
https://en.cppreference.com/w/cpp/keyword


** TODO Powerful

*** =+= Templates

In statically typed languages, especially those without a top type (e.g. =Object= in Java or =Any= in Scala), parametric polymorphism is necessary to write generic types (notably collections) and generic functions. Templates are like regular generics, except that they can also take integral and enum values as parameters in C++, and values of any type as parameters in D and ~ripl~. The ability to use values in addition to types as template parameters enables solutions to a number of problems that would be hard or impossible to solve otherwise, including:

1. Generic definitions of operations over static vectors and arrays of arbitrary length
2. Compile time dimensional analysis

Although templates in ~ripl~ have not yet been implemented (and as such have not yet been specified), example syntax can be seen in section [[=+= Type-Safe Discriminated Unions]].


*** =+= Compile-Time Evaluation

Compile-time evaluation (called compile-time function evaluation in D and constexpr in C++), is the ability to evaluate expressions without side-effects at compile time. This is not only useful for performing computations that would otherwise need to be performed at run time: when combined with templates, this is useful for type level programming.

The intent for ~ripl~ is that the compiler will be able to evaluate all pure expressions and functions, as long as their parameters parameters can be computed at compile time, and that these functions can operate on types in addition to values.


*** =+= Type Classes

Whereas template parameters in C++ and D are essentially duck-typed at compile time (supplying a type for which an operation is not defined to a template that requires this operation will fail during template expansion), generic parameters in some other languages can be constrained up front using a construct called type-classes in Haskell, called interfaces in Idris, and called traits in Rust. The type-class approach has a number of advantages over the duck-typing approach in that it can be used to inform clearer error messages (C++ template expansion error messages are notorious) and to establish clear type-level interfaces[fn:41].

[fn:41] A similiar construct called constraints and concepts is planned for C++20:
https://en.cppreference.com/w/cpp/language/constraints


*** =?= Lisp-style macros

Because ~ripl~ has a number of things in common with Lisp, including evaluation of expressions before run time, and a uniform syntax, it should be possible to experiment with adding some Lisp-style macros in future. Lisp macro systems are actually somewhat diverse between Common Lisp and Scheme, so some research would need to be done if one of these were to be emulated in ~ripl~.


** TODO COMMENT Notably Absent Features

*** TODO Object-Oriented Programming


* Comparison with Other Languages

# Should explain on what basis I chose these languages.

In order to compare ~ripl~ with other languages in an objective way, I identified a number of quantifiable language features to be used as a basis for comparison. I then evaluated each language across these criteria, assigning a value of =+= for features that were present, a value of =-= for features that were absent, and a value of =?= for features that were unclear or not applicable[fn:42], resulting in the language feature table in section [[Language Feature Table]].

Although this table is useful in detailing the features of each language, because it consists of 14 data-points in 31 dimensions it is hard to visualize the high-level structure of the data and relationships between the languages by looking at the table itself. Fortunately, there are a number of data visualization methods that can help to visualize this higher dimensional data. The results of these data visualization methods are presented in the following sections.

[fn:42] I chose to evaluate these languages using ternary values rather than more nuanced continuous values in an effort to reduce the subjectivity of the results. The symbols =+=, =?=, and =-= are converted to balanced ternary values of +1, 0, and -1 during export to the CSV file that is then used for data visualization.


** Notes on Statistical Methods

All distances calculated are Euclidean distances, all correlations are Pearson correlations, and all hierarchical clustering is done with the Ward-2 linkage method. The R code used to produce the figures in this document can be found at https://github.com/SongWithoutWords/ripl/blob/master/doc/figures/language-features/analysis.r.


** Language Feature Table
#+BEGIN_EXPORT latex
(See the next page.)
#+END_EXPORT


#+BEGIN_EXPORT latex
\begin{sidewaystable}[htbp]
\caption{Language Feature Table}
\resizebox{\textwidth}{!}{
\rowcolors{1}{}{gray!15}
#+END_EXPORT
#+NAME: language-feature-table
|                                  | C   | C++ | C#  | D   | Haskell | Java | JavaScript | LLVM-IR | ML  | Python | ~ripl~ | Rust | Scala | Scheme |
|----------------------------------+-----+-----+-----+-----+---------+------+------------+---------+-----+--------+--------+------+-------+--------|
| Garbage Collection               | =-= | =-= | =+= | =+= | =+=     | =+=  | =+=        | =?=     | =+= | =+=    | =?=    | =-=  | =+=   | =+=    |
| Explicit Indirection             | =+= | =+= | =-= | =+= | =-=     | =-=  | =-=        | =+=     | =-= | =-=    | =+=    | =+=  | =-=   | =-=    |
| Ownership System                 | =-= | =-= | =-= | =-= | =-=     | =-=  | =-=        | =-=     | =-= | =-=    | =?=    | =+=  | =-=   | =-=    |
| Memory Safety                    | =-= | =-= | =+= | =+= | =+=     | =+=  | =+=        | =-=     | =+= | =+=    | =+=    | =+=  | =+=   | =+=    |
| Static Typing                    | =+= | =+= | =+= | =+= | =+=     | =+=  | =-=        | =+=     | =+= | =-=    | =+=    | =+=  | =+=   | =-=    |
| Type Inference                   | =-= | =+= | =+= | =+= | =+=     | =-=  | =?=        | =-=     | =+= | =?=    | =+=    | =+=  | =+=   | =?=    |
| Sub-typing                       | =+= | =+= | =+= | =+= | =-=     | =+=  | =+=        | =-=     | =-= | =+=    | =+=    | =-=  | =+=   | =-=    |
| Parametric Polymorphism          | =-= | =+= | =+= | =+= | =+=     | =+=  | =?=        | =-=     | =+= | =?=    | =+=    | =+=  | =+=   | =?=    |
| Type Classes                     | =-= | =-= | =-= | =-= | =+=     | =-=  | =?=        | =-=     | =+= | =-=    | =+=    | =+=  | =-=   | =-=    |
| Type Level Programming           | =-= | =+= | =-= | =+= | =+=     | =-=  | =?=        | =-=     | =+= | =?=    | =+=    | =-=  | =+=   | =?=    |
| Ad-hoc Polymorphism              | =-= | =+= | =+= | =+= | =-=     | =+=  | =?=        | =-=     | =-= | =?=    | =+=    | =-=  | =+=   | =?=    |
| Classical Inheritance            | =-= | =+= | =+= | =+= | =-=     | =+=  | =-=        | =-=     | =-= | =+=    | =-=    | =-=  | =+=   | =-=    |
| Prototypal Inheritance           | =-= | =-= | =-= | =-= | =-=     | =-=  | =+=        | =-=     | =-= | =-=    | =-=    | =-=  | =-=   | =-=    |
| Strict Evaluation                | =+= | =+= | =+= | =+= | =-=     | =+=  | =+=        | =+=     | =+= | =+=    | =+=    | =+=  | =+=   | =+=    |
| Type-safe Discriminated Unions   | =-= | =-= | =-= | =+= | =+=     | =-=  | =-=        | =-=     | =+= | =-=    | =+=    | =+=  | =+=   | =-=    |
| Null Safety                      | =-= | =-= | =-= | =-= | =+=     | =-=  | =-=        | =-=     | =+= | =-=    | =+=    | =+=  | =-=   | =+=    |
| Pattern Matching                 | =-= | =-= | =-= | =-= | =+=     | =-=  | =-=        | =-=     | =+= | =-=    | =+=    | =+=  | =+=   | =-=    |
| Mutable Data                     | =+= | =+= | =+= | =+= | =-=     | =+=  | =+=        | =+=     | =+= | =+=    | =+=    | =+=  | =+=   | =+=    |
| Immutable Data                   | =-= | =+= | =-= | =+= | =+=     | =-=  | =-=        | =-=     | =+= | =-=    | =+=    | =+=  | =+=   | =-=    |
| Constraints on Mutability        | =-= | =+= | =-= | =+= | =-=     | =-=  | =-=        | =-=     | =-= | =-=    | =+=    | =+=  | =-=   | =-=    |
| Constraints on Function Purity   | =-= | =-= | =-= | =+= | =+=     | =-=  | =-=        | =-=     | =-= | =-=    | =+=    | =-=  | =-=   | =-=    |
| C-style Syntax                   | =+= | =+= | =+= | =+= | =-=     | =+=  | =+=        | =-=     | =-= | =+=    | =-=    | =+=  | =+=   | =-=    |
| Header Files                     | =+= | =+= | =-= | =-= | =-=     | =-=  | =-=        | =-=     | =-= | =-=    | =-=    | =-=  | =-=   | =-=    |
| Whitespace Sensitive             | =-= | =-= | =-= | =-= | =+=     | =-=  | =-=        | =-=     | =-= | =+=    | =+=    | =-=  | =-=   | =-=    |
| Uniform Syntax                   | =-= | =-= | =-= | =-= | =-=     | =-=  | =-=        | =-=     | =-= | =-=    | =+=    | =-=  | =-=   | =+=    |
| Expression Oriented              | =-= | =-= | =-= | =-= | =+=     | =-=  | =-=        | =-=     | =+= | =-=    | =+=    | =+=  | =+=   | =+=    |
| Top Level Functions              | =+= | =+= | =-= | =+= | =+=     | =-=  | =+=        | =+=     | =+= | =+=    | =+=    | =+=  | =-=   | =+=    |
| Methods                          | =-= | =+= | =+= | =+= | =-=     | =+=  | =+=        | =-=     | =?= | =+=    | =-=    | =-=  | =+=   | =-=    |
| Uniform Function Call Syntax     | =?= | =-= | =?= | =+= | =?=     | =?=  | =-=        | =-=     | =?= | =-=    | =+=    | =+=  | =?=   | =?=    |
| Compile Time Function Evaluation | =-= | =+= | =-= | =+= | =-=     | =-=  | =?=        | =-=     | =-= | =?=    | =+=    | =-=  | =-=   | =?=    |
| Closures                         | =-= | =+= | =+= | =+= | =+=     | =+=  | =+=        | =-=     | =+= | =+=    | =+=    | =+=  | =+=   | =+=    |

#+BEGIN_EXPORT latex
} % end resizebox
\end{sidewaystable}
\pagebreak % without this pagebreak, the table may not land in the right section
#+END_EXPORT

#+NAME: export-language-feature-table-to-csv
#+BEGIN_SRC emacs-lisp :var table=language-feature-table :results none :exports none :colnames no
(with-temp-file "doc/figures/language-features/table.csv"
  (insert (format "%s"
    (concat
      (mapconcat
        (lambda (row)
          (mapconcat
            (lambda (cell)
              (cond
                ((equal cell "~ripl~") "ripl")
                ((equal cell "=-=") "-1")
                ((equal cell "=?=") "+0")
                ((equal cell "=+=") "+1")
                (t cell)))
            (remove "" row) ","))
        table "\n")
    "\n"))))
#+END_SRC

#+NAME: language-feature-table-balanced-ternary
#+BEGIN_SRC emacs-lisp :var table=language-feature-table :results value :exports none :colnames no
(mapcar
  (lambda (row)
    (mapcar
      (lambda (cell)
        (cond
          ((equal cell "~ripl~") "ripl")
          ((equal cell "=-=") -1)
          ((equal cell "=?=") +0)
          ((equal cell "=+=") +1)
          (t cell)))
    row))
  table)
#+END_SRC

#+RESULTS: language-feature-table-balanced-ternary
|                                  |  C | C++ | C# |  D | Haskell | Java | JavaScript | LLVM-IR | ML | Python | ripl | Rust | Scala | Scheme |
| Garbage Collection               | -1 |  -1 |  1 |  1 |       1 |    1 |          1 |       0 |  1 |      1 |    0 |   -1 |     1 |      1 |
| Explicit Indirection             |  1 |   1 | -1 |  1 |      -1 |   -1 |         -1 |       1 | -1 |     -1 |    1 |    1 |    -1 |     -1 |
| Ownership System                 | -1 |  -1 | -1 | -1 |      -1 |   -1 |         -1 |      -1 | -1 |     -1 |    0 |    1 |    -1 |     -1 |
| Memory Safety                    | -1 |  -1 |  1 |  1 |       1 |    1 |          1 |      -1 |  1 |      1 |    1 |    1 |     1 |      1 |
| Static Typing                    |  1 |   1 |  1 |  1 |       1 |    1 |         -1 |       1 |  1 |     -1 |    1 |    1 |     1 |     -1 |
| Type Inference                   | -1 |   1 |  1 |  1 |       1 |   -1 |          0 |      -1 |  1 |      0 |    1 |    1 |     1 |      0 |
| Sub-typing                       |  1 |   1 |  1 |  1 |      -1 |    1 |          1 |      -1 | -1 |      1 |    1 |   -1 |     1 |     -1 |
| Parametric Polymorphism          | -1 |   1 |  1 |  1 |       1 |    1 |          0 |      -1 |  1 |      0 |    1 |    1 |     1 |      0 |
| Type Classes                     | -1 |  -1 | -1 | -1 |       1 |   -1 |          0 |      -1 |  1 |     -1 |    1 |    1 |    -1 |     -1 |
| Type Level Programming           | -1 |   1 | -1 |  1 |       1 |   -1 |          0 |      -1 |  1 |      0 |    1 |   -1 |     1 |      0 |
| Ad-hoc Polymorphism              | -1 |   1 |  1 |  1 |      -1 |    1 |          0 |      -1 | -1 |      0 |    1 |   -1 |     1 |      0 |
| Classical Inheritance            | -1 |   1 |  1 |  1 |      -1 |    1 |         -1 |      -1 | -1 |      1 |   -1 |   -1 |     1 |     -1 |
| Prototypal Inheritance           | -1 |  -1 | -1 | -1 |      -1 |   -1 |          1 |      -1 | -1 |     -1 |   -1 |   -1 |    -1 |     -1 |
| Strict Evaluation                |  1 |   1 |  1 |  1 |      -1 |    1 |          1 |       1 |  1 |      1 |    1 |    1 |     1 |      1 |
| Type-safe Discriminated Unions   | -1 |  -1 | -1 |  1 |       1 |   -1 |         -1 |      -1 |  1 |     -1 |    1 |    1 |     1 |     -1 |
| Null Safety                      | -1 |  -1 | -1 | -1 |       1 |   -1 |         -1 |      -1 |  1 |     -1 |    1 |    1 |    -1 |      1 |
| Pattern Matching                 | -1 |  -1 | -1 | -1 |       1 |   -1 |         -1 |      -1 |  1 |     -1 |    1 |    1 |     1 |     -1 |
| Mutable Data                     |  1 |   1 |  1 |  1 |      -1 |    1 |          1 |       1 |  1 |      1 |    1 |    1 |     1 |      1 |
| Immutable Data                   | -1 |   1 | -1 |  1 |       1 |   -1 |         -1 |      -1 |  1 |     -1 |    1 |    1 |     1 |     -1 |
| Constraints on Mutability        | -1 |   1 | -1 |  1 |      -1 |   -1 |         -1 |      -1 | -1 |     -1 |    1 |    1 |    -1 |     -1 |
| Constraints on Function Purity   | -1 |  -1 | -1 |  1 |       1 |   -1 |         -1 |      -1 | -1 |     -1 |    1 |   -1 |    -1 |     -1 |
| C-style Syntax                   |  1 |   1 |  1 |  1 |      -1 |    1 |          1 |      -1 | -1 |      1 |   -1 |    1 |     1 |     -1 |
| Header Files                     |  1 |   1 | -1 | -1 |      -1 |   -1 |         -1 |      -1 | -1 |     -1 |   -1 |   -1 |    -1 |     -1 |
| Whitespace Sensitive             | -1 |  -1 | -1 | -1 |       1 |   -1 |         -1 |      -1 | -1 |      1 |    1 |   -1 |    -1 |     -1 |
| Uniform Syntax                   | -1 |  -1 | -1 | -1 |      -1 |   -1 |         -1 |      -1 | -1 |     -1 |    1 |   -1 |    -1 |      1 |
| Expression Oriented              | -1 |  -1 | -1 | -1 |       1 |   -1 |         -1 |      -1 |  1 |     -1 |    1 |    1 |     1 |      1 |
| Top Level Functions              |  1 |   1 | -1 |  1 |       1 |   -1 |          1 |       1 |  1 |      1 |    1 |    1 |    -1 |      1 |
| Methods                          | -1 |   1 |  1 |  1 |      -1 |    1 |          1 |      -1 |  0 |      1 |   -1 |   -1 |     1 |     -1 |
| Uniform Function Call Syntax     |  0 |  -1 |  0 |  1 |       0 |    0 |         -1 |      -1 |  0 |     -1 |    1 |    1 |     0 |      0 |
| Compile Time Function Evaluation | -1 |   1 | -1 |  1 |      -1 |   -1 |          0 |      -1 | -1 |      0 |    1 |   -1 |    -1 |      0 |
| Closures                         | -1 |   1 |  1 |  1 |       1 |    1 |          1 |      -1 |  1 |      1 |    1 |    1 |     1 |      1 |

** Hierarchical Clustering of Languages

One method that is useful for visualizing higher-dimensional data is hierarchical clustering, which works by assigning each data point to its own group, and then repeatedly combining the two nearest groups (in n-dimensional space) until all data points have been organized into a binary tree. When applied to this data set, this process yields a taxonomy of programming languages based on the features considered in the language features table:

#+CAPTION: Hierarchical Clustering of Languages
#+ATTR_LATEX: :width 12cm :placement [H]
[[file:doc/figures/language-features/hierarchical-clustering-of-languages.png]]

The results are consistent with my understanding of the languages considered, and help to place ripl in context. An annotated version of the tree above might look something like this:

- Languages considered
  - Statically typed, functional languages
    - ML-like (ML, Haskell)
    - Other (ripl, Rust)
  - Languages that are not both statically typed and functional
    - Low-level (C, LLVM-IR)
    - Higher-level
      - Dynamically typed
        - Scheme
        - Python, JavaScript
      - Statically typed
        - C++ and D (which was intended as a successor of C++)
        - Java-derived languages
          - Scala (the height at which it branches indicates it's disimilarity to C# and Java)
          - Java and C# (the most similar of any two languages considered)


** Distance of ~ripl~ from Other Languages

Based on the data:

#+NAME: distance-of-ripl-from-other-languages
#+BEGIN_SRC R :var language.feature.table=language-feature-table-balanced-ternary :exports results :results output raw
library(ascii)
options(asciiType="org")

df = as.data.frame(language.feature.table)
colnames(df) = df[1,]
rownames(df) = df[,1]
df = df[-1,-1]

distance = as.matrix(dist(t(df)))

from.ripl = data.frame(sort(distance["ripl",])[-1])
from.ripl = cbind(rownames(from.ripl), from.ripl)
colnames(from.ripl) = c("Language", "Distance from ~ripl~")

ascii(from.ripl, include.rownames=FALSE)
#+END_SRC

#+ATTR_LATEX: :placement [H] :caption \caption{Languages Sorted by Distance from \texttt{ripl}} \rowcolors{1}{}{gray!15}
#+RESULTS: distance-of-ripl-from-other-languages
| Language   | Distance from ~ripl~ |
|------------+----------------------|
| Rust       |                 5.83 |
| Haskell    |                 5.92 |
| ML         |                 6.00 |
| D          |                 6.16 |
| Scheme     |                 6.93 |
| Scala      |                 7.14 |
| C++        |                 7.62 |
| Python     |                 8.19 |
| JavaScript |                 8.25 |
| C#         |                 8.43 |
| Java       |                 8.66 |
| LLVM-IR    |                 8.77 |
| C          |                 8.89 |


** TODO Hierarchical Clustering of Language Features

Incidentally, by running hierarchical clustering on the transpose of our table, it's possible classify the language features it contains by the programming languages in which they occur:

#+CAPTION: Hierarchical Clustering of Language Feature Correlation by Language Excluding ~ripl~
#+ATTR_LATEX: :width 14cm :placement [H]
[[file:doc/figures/language-features/hierarchical-clustering-of-language-features-excluding-ripl.png]]

The result of this exercise provides some interesting insights: in particular, it suggests a strong correlation between garbage collection and memory safety (which may come as no surprise), and between pattern matching, type-safe discriminated unions and null-safety.

** TODO Heatmap of Distances Between Languages

#+CAPTION: Heatmap of Distances Between Languages
#+ATTR_LATEX: :width 16cm :placement [H]
[[file:doc/figures/language-features/heatmap-of-language.png]]

** TODO Heatmap of Correlations Between Language Features
Important to keep in mind is that this is descriptive and not predictive statistics

#+CAPTION: Heatmap of Correlations Between Language Features
#+ATTR_LATEX: :width 20cm :placement [H]
[[file:doc/figures/language-features/language-feature-correlation-heatmap-pearson.png]]

** TODO Multidimensional Scaling of Languages

#+CAPTION: Multidimensional Scaling of Languages
#+ATTR_LATEX: :width 14cm :placement [H]
[[file:doc/figures/language-features/multidimensional-scaling-of-languages-non-metric.png]]

** TODO Discussion of specific languages


* TODO Implementation

** Lexing
The lexer of the ~ripl~ compiler is quite straightforward. It takes the string input of the source code to be compiled and breaks it down into tokens, such as symbols, strings, and numbers, in addition to tracking changes in indentation and emitting indent and dedent tokens. These tokens are then handed off to the parser.


** Parsing
Although earlier versions of ~ripl~ with a more complicated grammar used a parser generator (Happy when the compiler was written in Haskell, and ANTLR after it was ported to Scala), since the adoption of a Lisp-like syntax inspired by   [[https://sourceforge.net/p/readable/wiki/Home/][Readable Lisp S-expressions]][fn:4]    (as described in [[Brief History of =ripl='s Syntax]]), the parser is now written directly in Scala, and the implementation is about half the length it was with ANTLR.


** Post-Parsing
Post parsing is a step that converts free-form s-expressions into ~ripl~'s untyped abstract syntax tree, and so performs conversions like =SExp(Name("if"), Name("a"), Name("b"), Name("c"))= to =If(Name("a"), Name("b"), Name("c"))=. It does such little work, that it might be wise in a future to fold it into the parsing step to cut down on unnecessary traversals. The only advantage of performing this as a separate step is that it is more modular and can be tested separately.

** Reduction
Reduction is by far the most complicated and important aspect of the ~ripl~ compiler. It is the semantic stage that is responsible for overload resolution, namespacing, compile time evaluation, type inference, and type checking. Presently it works by reducing all definitions in the AST lazily, so that evaluation of their results can be deferred until required by another definition.

The only problem with this lazy approach occurs with recursive definitions, which would loop endlessly as each attempt to compute their result would trigger another computation of their result. This is resolved by maintaining a history of visited definitions to detect cycles, and requiring recursive functions to have an explicit return type.


** Code Generation
Code generation is the process of translating the post-reduction ~ripl~ AST into the LLVM-IR AST. It is pretty straightforward and relies on a monad ported from llvm-hs called ~IRBuilder~ to keep track of a name supply, local bindings, and blocks.


** LLVM-Bindings
The LLVM-bindings are a port of the llvm-hs bindings and llvm-hs-pretty printer from Haskell to Scala, that enable the LLVM-IR AST to be represented and serialized as text.

\pagebreak
** Detailed Implementation Status

#+LATEX: \begin{multicols}{2}
- [X] Lexing
  - [X] Comments
  - [X] Indentation
  - [X] Numbers
  - [X] Names
  - [X] Special symbols (e.g. =~=, =@=, =^=)
  - [X] Strings
- [-] Parsing
  - [X] S-expressions
  - [X] S-expressions delimited by whitespace
  - [ ] Infix notation (e.g. ={x + y}=)
  - [ ] Prefix modifiers (e.g. =~=, =^=)
  - [ ] Selection syntax (e.g. =math.pi=)
- [-] Post-Parsing
  - [X] Application
  - [X] Function definition
  - [X] Global variables/constants
  - [X] If-expressions
  - [X] Structs
  - [ ] Implicit conversions
  - [ ] Local Variables
  - [ ] Pattern matching
  - [ ] Prefix modifiers (e.g. =~=, =^=)
  - [ ] Templates
  - [ ] Type Classes
  - [ ] Unions
- [-] Reduction
  - [X] Built-in arithmetic and logic
  - [X] Compile-time expression evaluation
  - [X] If-expressions
  - [X] Implicit conversions
  - [X] Lambdas
  - [X] Overloading
  - [X] Namespaces
  - [X] Recursive functions
  - [X] Selection
  - [X] Structs
  - [X] Type-checking
  - [X] Type-inference
  - [ ] Arrays
  - [ ] Compile-time function evaluation
  - [ ] Constraints on purity
  - [ ] Constraints on mutability
  - [ ] Local variables
  - [ ] Pattern Matching
  - [ ] Templates
  - [ ] Type Classes
  - [ ] Unions
- [-] Code Generation
  - [X] Application
  - [X] Built-in arithmetic and logic
  - [X] Functions
  - [X] If-expressions
  - [X] Structs
  - [ ] Arrays
  - [ ] Closure and lambdas
  - [ ] Local Variables
  - [ ] Pattern matching
  - [ ] Strings
  - [ ] Templates
  - [ ] Unions
- [X] LLVM-Bindings
  - [X] Representation of LLVM AST
  - [X] Serialization of LLVM AST
#+Latex: \end{multicols}


* COMMENT Misc TODO

** TODO Prose
*** TODO Avoid usage of "great" as an adjective
*** TODO Avoid shared text between abstract and introduction
*** TODO Should write a summary
*** TODO Lowercase ripl in language feature table and graphs
*** TODO Remove dashes in language feature variable names
*** TODO Caption the figures (and remove titles from the figures themselves)
*** TODO Specify somewhere that ^ means reference in ~ripl~
*** TODO Spell-check before you submit
** TODO Graphs
*** DONE Move R code into its own file (it sortof sucks writing it in org mode)

*** DONE Get rid of PCA, MDS is better

*** DONE Exclude ripl from hierarchical clustering of features

*** DONE Experiment with other hierarchical clustering methods
The alternatives weren't as good as ward.d2

*** TODO Correlation analysis of language features

*** DONE Ensure that heatmap agrees with hierarchical clustering

*** TODO Get rid of classic MDS

*** TODO Scale the images appropriately for the paper, both for markdown and pdf export

*** TODO Consider removing plot titles

*** DONE Spread language feature table across multiple pages for latex export

*** TODO Try adding footnotes to the table to provide additional information, does it work with csv and latex export?

*** TODO Consider adding Dart and Lua as additional languages

*** TODO Consider heatmaps and multidimensional scaling of language features

*** TODO Use unicode sharp sign for C#
# Câ¯



* Footnotes

* COMMENT Local Variables

# Local Variables:
# org-src-preserve-indentation: t
# org-src-fontify-natively: t
# org-export-latex-listings: t
# org-latex-listings: t
# org-babel-sh-command: "./doc/scripts/redirect-stderr.sh"
# org-latex-listings-langs: '(racket "ripl")
# end:
